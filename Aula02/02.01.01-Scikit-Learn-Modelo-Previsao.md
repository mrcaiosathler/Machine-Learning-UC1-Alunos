# Treinando um modelo de classifica√ß√£o

> O modelo ser√° treinado para prever a vari√°vel `categoria` (que pode ser `"A"` ou `"B"`) com base nas demais colunas do dataset, ap√≥s todo o pr√©-processamento que fizemos.

## üéØ Objetivo

Treinar um modelo de **Regress√£o Log√≠stica** usando:
- Dados j√° pr√©-processados (`df_final`)
- Divis√£o entre dados de treino e teste
- M√©tricas de avalia√ß√£o


## ‚úÖ Passos detalhados

### 1. Importar bibliotecas necess√°rias

:snake: **C√≥digo**

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
```

:pushpin: **Explica√ß√£o**

| Biblioteca / Classe                    | Finalidade Principal                                      |
|---------------------------------------|------------------------------------------------------------|
| `train_test_split`                    | Dividir dados em conjuntos de treino e teste              |
| `LogisticRegression`                  | Treinar um modelo de classifica√ß√£o                        |
| `accuracy_score`                      | Medir a porcentagem de acertos do modelo                  |
| `classification_report`               | Relat√≥rio detalhado com precis√£o, recall e f1-score       |
| `confusion_matrix`                    | Visualizar os tipos de erros do modelo                    |


### 2. Separar as vari√°veis explicativas (`X`) e a vari√°vel alvo (`y`)

Vamos considerar que seu DataFrame final se chama `df_final` e cont√©m as colunas:

- Num√©ricas padronizadas: `idade`, `renda`, `nota`
- Vari√°veis categ√≥ricas codificadas: ex: `cidade_Sao Paulo`, `feedback_Bom`, etc.
- E a vari√°vel alvo √©: `categoria` (com valores `'A'` e `'B'`)

:snake: **C√≥digo**

```python
# X = todas as colunas, exceto 'categoria'
X = df_final.drop('categoria', axis=1)

# y = a coluna que queremos prever
y = df_final['categoria']
```

:pushpin: **Explica√ß√£o**

Prepara os dados para um modelo de **machine learning** separando:

- As **vari√°veis explicativas (features)** ‚Üí armazenadas em `X`
- A **vari√°vel alvo (target)** ‚Üí armazenada em `y`
- **`axis=1`**: significa que estamos removendo uma **coluna**, n√£o uma linha.

Ou seja:
- `X`: o que o modelo usa para aprender
- `y`: o que o modelo deve prever

:bulb: **Resumo**:

| Vari√°vel | O que representa                          | Tipo             |
|---------|--------------------------------------------|------------------|
| `X`     | Dados de entrada (features)                | DataFrame        |
| `y`     | Valor que queremos prever (target)         | S√©rie (coluna)   |


### 3. Dividir os dados em conjuntos de treino e teste

:snake: **C√≥digo**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,     # 20% dos dados ser√£o usados para teste
    random_state=42,   # garantir reprodutibilidade
    stratify=y         # manter propor√ß√£o das classes em treino e teste
)
```

:pushpin: **Explica√ß√£o**

Esse c√≥digo divide os dados em dois grupos:
- Conjunto de treino (X_train, y_train) : usado para treinar o modelo
- Conjunto de teste (X_test, y_test) : usado para avaliar como o modelo se sai com dados novos e n√£o vistos

> ‚ö†Ô∏è O par√¢metro `stratify=y` garante que a propor√ß√£o de `"A"` e `"B"` seja mantida nos conjuntos de treino e teste.

| Parte | O que faz |
|------|-----------|
| `train_test_split(...)` | Fun√ß√£o que divide os dados em conjuntos de treino e teste |
| `X, y` | S√£o os dados de entrada (features) e o alvo (o que queremos prever) |
| `test_size=0.2` | Define que **20% dos dados** v√£o para o conjunto de teste (80% para treino) |
| `random_state=42` | Garante que a divis√£o seja **sempre a mesma** (para reprodutibilidade) |
| `stratify=y` | Mant√©m a **mesma propor√ß√£o de classes** em `y` nos conjuntos de treino e teste |

Se voc√™ tem 100 registros e `test_size=0.2`:

- **80 registros** v√£o para treino (`X_train`, `y_train`)
- **20 registros** v√£o para teste (`X_test`, `y_test`)

E com `stratify=y`, se 60% dos dados s√£o `"A"` e 40% s√£o `"B"`, essa propor√ß√£o ser√° mantida nos dois conjuntos.

üí° **Por que isso √© importante?**

- **Evita overfitting**: Treinar e testar com os mesmos dados pode levar a um modelo que "decora" as respostas.

- **Reprodutibilidade**: Com `random_state`, voc√™ garante que outros obtenham os mesmos resultados.

- **Propor√ß√£o balanceada**: Com `stratify=y`, o modelo √© avaliado com base em uma amostra representativa.

### 4. Criar e treinar o modelo de Regress√£o Log√≠stica

Este c√≥digo **cria e treina** um modelo de **Regress√£o Log√≠stica**, que √© um algoritmo comum usado para **classifica√ß√£o** (por exemplo: prever se algo √© `"A"` ou `"B"`).

:snake: **C√≥digo**
```python
# Aumentamos max_iter para garantir converg√™ncia
modelo = LogisticRegression(max_iter=1000)  

# Treinando o modelo
modelo.fit(X_train, y_train)
```

> ‚ö†Ô∏è `max_iter=1000`: algumas vezes a regress√£o log√≠stica precisa de mais itera√ß√µes para convergir; aumentamos esse limite para evitar avisos.

O modelo aprende as rela√ß√µes entre as **vari√°veis de entrada** (`X_train`) e a **vari√°vel de sa√≠da** (`y_train`), para depois fazer previs√µes.

| Parte do c√≥digo              | Finalidade                                     |
|-----------------------------|------------------------------------------------|
| `LogisticRegression(...)`   | Cria o modelo de classifica√ß√£o                 |
| `max_iter=1000`             | Garante que o modelo tente convergir melhor    |
| `.fit(X_train, y_train)`    | Ensina o modelo com os dados de treino         |

---

### 5. Fazer previs√µes no conjunto de teste

Esse c√≥digo usa um modelo de machine learning j√° treinado para fazer previs√µes em novos dados (neste caso, os dados de teste).

```python
y_pred = modelo.predict(X_test)
```

**Explica√ß√£o:**

- **`X_test`**: s√£o os dados de entrada que o modelo **nunca viu antes** (dados de teste).
- **`.predict()`**: √© o m√©todo usado para o modelo **prever resultados** com base nesses novos dados.
- **`y_pred`**: √© onde armazenamos as **previs√µes feitas pelo modelo** (ou seja, quais valores ele acha que `y` deve ter para cada linha de `X_test`).

Se o modelo foi treinado para prever se um cliente pertence √† categoria `"A"` ou `"B"`, ent√£o:

- `X_test`: s√£o os dados desses clientes que o modelo n√£o viu durante o treino
- `y_pred`: ser√° uma lista com as **previs√µes** do modelo para cada cliente:  
  Exemplo: `['A', 'B', 'B', 'A', ...]`


### 6. Avaliar o desempenho do modelo

#### a) Acur√°cia: porcentagem de acertos

Este c√≥digo **avalia o desempenho** de um modelo de machine learning, medindo a **porcentagem de acertos** nas previs√µes feitas em dados de teste.

```python
acuracia = accuracy_score(y_test, y_pred)
print(f'Acur√°cia do modelo: {acuracia:.2f}')
```

**Explica√ß√£o**:

- **`accuracy_score()`**: √© uma fun√ß√£o do Scikit-learn que calcula a **acur√°cia**, ou seja, a porcentagem de previs√µes corretas.
- **`y_test`**: s√£o os valores reais (corretos) que o modelo deveria prever.
- **`y_pred`**: s√£o as previs√µes feitas pelo modelo.
- **Resultado:** um n√∫mero entre 0 e 1 (ex: `0.85` = 85% de acerto)

Esse √© um dos m√©todos mais simples e comuns para avaliar modelos de classifica√ß√£o.

#### b) Relat√≥rio completo: precis√£o, recall, f1-score

Este c√≥digo mostra um **relat√≥rio completo com m√©tricas de avalia√ß√£o** do modelo de classifica√ß√£o.

Ele vai al√©m da acur√°cia e mostra:
- **Precis√£o**
- **Recall (ou sensibilidade)**
- **F1-score**
- **Suporte** (quantidade de amostras por classe)

:snake: **C√≥digo**
```python
print(classification_report(y_test, y_pred))
```

üéØ **O que cada parte faz**:

- **`classification_report()`**:  
  Fun√ß√£o do Scikit-learn que gera um relat√≥rio com as m√©tricas acima para cada classe (`"A"` e `"B"` no seu caso).

- **`y_test`**:  
  Os valores reais (corretos) do target.

- **`y_pred`**:  
  As previs√µes feitas pelo modelo.


  
üîç **Exemplo de sa√≠da:**

```
              precision    recall  f1-score   support

           A       0.83      0.87      0.85        15
           B       0.88      0.83      0.85        18

    accuracy                           0.85        33
   macro avg       0.85      0.85      0.85        33
weighted avg       0.85      0.85      0.85        33
```

| M√©trica       | O que mede? |
|---------------|-------------|
| **Precision** | Dos que o modelo disse ser `"A"`, quantos realmente eram `"A"`? |
| **Recall**    | Dos que realmente eram `"A"`, quantos o modelo acertou? |
| **F1-score**  | M√©dia entre precis√£o e recall (boa para dados desbalanceados) |
| **Support**   | Quantas amostras tinham em cada classe |

A **accuracy** (acur√°cia) √© a porcentagem de previs√µes corretas feitas pelo modelo, ou seja, quantos resultados ele acertou em rela√ß√£o ao total. 

J√° o **macro avg** √© a m√©dia das m√©tricas (como precis√£o, recall e F1-score) calculada sem considerar o n√∫mero de amostras por classe, dando o mesmo peso para cada classe ‚Äî o que √© √∫til quando voc√™ quer avaliar classes minorit√°rias. 

Por outro lado, o **weighted avg** tamb√©m calcula a m√©dia dessas m√©tricas, mas leva em conta a propor√ß√£o de amostras em cada classe , dando mais peso √†s classes maiores, o que pode ser mais representativo quando as classes est√£o desbalanceadas. 

Essas m√©tricas ajudam a entender melhor o desempenho do modelo al√©m da acur√°cia geral.


#### c) Matriz de confus√£o (visualiza√ß√£o dos erros)

Este c√≥digo exibe a **matriz de confus√£o**, que √© uma tabela que mostra **quantas previs√µes foram corretas ou incorretas** em cada classe.

```python
print(confusion_matrix(y_test, y_pred))
```

üîç **O que cada parte faz**:

- **`confusion_matrix()`**:  
  Fun√ß√£o do Scikit-learn que calcula a matriz de confus√£o com base nos valores reais (`y_test`) e nas previs√µes do modelo (`y_pred`).

- **`y_test`**:  
  Os valores reais (corretos) que o modelo deveria prever.

- **`y_pred`**:  
  As previs√µes feitas pelo modelo nos dados de teste.



**Exemplo de sa√≠da**:

```
[[13  2]
 [ 3 15]]
```

**Isso significa**:

|                | Previsto como A | Previsto como B |
|----------------|------------------|------------------|
| **Realmente A** | 13 (Verdadeiro Positivo) | 2 (Falso Negativo) |
| **Realmente B** | 3 (Falso Positivo)       | 15 (Verdadeiro Negativo) |

A matriz de confus√£o ajuda a entender **onde o modelo errou e acertou**, mostrando:
- Quantos ele acertou por classe
- Quantos ele confundiu entre as classes

---

## ‚úÖ Exemplo de sa√≠da poss√≠vel

Se o modelo estiver bom, voc√™ ver√° algo como:

```
Acur√°cia do modelo: 0.85
              precision    recall  f1-score   support

           A       0.83      0.87      0.85        15
           B       0.88      0.83      0.85        18

    accuracy                           0.85        33
   macro avg       0.85      0.85      0.85        33
weighted avg       0.85      0.85      0.85        33

[[13  2]
 [ 3 15]]
```

## üß† Interpreta√ß√£o r√°pida

- **Acur√°cia = 85%**: o modelo acertou 85% das previs√µes.
- **Precision (precis√£o)**: percentual de previs√µes positivas corretas.
- **Recall (revoca√ß√£o)**: percentual de verdadeiros positivos identificados.
- **F1-Score**: m√©dia harm√¥nica entre precis√£o e recall.
- **Matriz de Confus√£o**:
  - Verdadeiros Positivos (VP): 13 (classe A correta)
  - Falsos Negativos (FN): 2 (previu B, mas era A)
  - Falsos Positivos (FP): 3 (previu A, mas era B)
  - Verdadeiros Negativos (VN): 15 (classe B correta)



## 7. Salvar o modelo treinado em um arquivo

No Scikit-learn, os modelos podem ser salvos usando:

- `joblib`: mais eficiente para objetos grandes (como modelos de ML)
- `pickle`: m√©todo mais antigo, mas tamb√©m funcional

Vamos usar o `joblib`, por ser mais r√°pido nesse caso.


```python
dump(modelo, 'modelo_regressao_logistica.joblib')
print("\nModelo salvo como 'modelo_regressao_logistica.joblib'")
```

A linha `dump(modelo, 'modelo_regressao_logistica.joblib')` √© usada para salvar um modelo de machine learning treinado em um arquivo no disco. 

Ela faz parte da biblioteca joblib, que permite serializar e salvar objetos do Python ‚Äî especialmente √∫teis para modelos grandes e complexos, como os criados com o Scikit-learn. 

Nesse caso, o modelo chamado modelo (no exemplo, um modelo de Regress√£o Log√≠stica) √© salvo no arquivo 'modelo_regressao_logistica.joblib', permitindo que ele seja reutilizado posteriormente sem a necessidade de trein√°-lo novamente, bastando carreg√°-lo com a fun√ß√£o load() do pr√≥prio joblib.

## üì¶ Como carregar o modelo depois (opcional)

Se quiser usar o modelo salvo em outro script, basta usar:

```python
from joblib import load

# Carregar o modelo
modelo_carregado = load('modelo_regressao_logistica.joblib')

# Usar o modelo para prever novos dados
#novas_previsoes = modelo_carregado.predict(X_novo)
```

| Etapa | Finalidade |
|-------|------------|
| `from joblib import dump` | Importa a ferramenta para salvar o modelo |
| `dump(modelo, 'nome_do_arquivo.joblib')` | Salva o modelo treinado em um arquivo |
| Futuro `load(...)` | Permite recarregar o modelo em outro momento |



## üìå Resumo do fluxo

| Etapa                     | O que foi feito                                             |
|--------------------------|-------------------------------------------------------------|
| Definir `X` e `y`        | Escolher features e alvo                                    |
| Dividir os dados         | Usar `train_test_split()`                                   |
| Treinar o modelo         | `LogisticRegression()`                                      |
| Fazer previs√µes          | `predict()`                                                 |
| Avaliar o modelo         | `accuracy_score()`, `classification_report()`, `confusion_matrix()` |

