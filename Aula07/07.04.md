# **Compara√ß√£o e Sele√ß√£o de Arquiteturas em Machine Learning**

## üéØ Objetivo da Aula

Nesta aula, verificarmos como **escolher a melhor arquitetura (modelo ou estrutura)** para resolver problemas de **machine learning**, considerando as caracter√≠sticas dos dados, os recursos dispon√≠veis e o objetivo do projeto.

Vamos discutir:
- Como identificar o **tipo de dado** que estamos lidando.
- Quais **modelos** funcionam melhor com cada tipo de dado.
- Quando priorizar **desempenho ou simplicidade**.
- Como escolher entre diferentes **arquiteturas** com base em crit√©rios pr√°ticos.


## üß† Introdu√ß√£o ao Problema

Imagine que voc√™ foi contratado para desenvolver um sistema que:

1. **Detecte** c√¢ncer a partir de exames m√©dicos (dados tabulares),
2. **Reconhe√ßa objetos** em fotos (imagens),
3. **Classifique sentimentos** em mensagens (texto),
4. **Preveja vendas** futuras com base no hist√≥rico (s√©ries temporais).

**Pergunta:** Voc√™ usaria o mesmo modelo para todos esses casos?

üí° **Resposta curta:** N√£o! Cada tipo de problema precisa de uma abordagem diferente.

## üîç Parte 1: Entendendo o Tipo de Dado

Antes de escolher uma arquitetura, √© essencial entender **qual tipo de dado voc√™ tem**.

### Tipos Comuns de Dados:

| Tipo de Dado        | Exemplo                          | Modelos Recomendados                      |
|---------------------|----------------------------------|-------------------------------------------|
| **Dados Estruturados** (tabelas) | Planilhas, bases SQL             | Regress√£o Log√≠stica, Random Forest, XGBoost |
| **Imagens**           | Fotos, radiografias              | CNN (Convolutional Neural Networks)       |
| **Texto**             | Tweets, avalia√ß√µes               | RNN, LSTM, Transformers (BERT, etc.)     |
| **S√©ries Temporais**  | Vendas mensais, pre√ßos de a√ß√µes  | ARIMA, Prophet, LSTM, Transformer TimeSeries |


**Recapitulando**:

1. **Regress√£o linear**
    - √© um modelo estat√≠stico utilizado para prever o valor de uma vari√°vel dependente (alvo) com base em uma ou mais vari√°veis independentes (caracter√≠sticas), assumindo uma rela√ß√£o linear entre elas. 
    - O objetivo do modelo √© encontrar a melhor reta (ou hiperplano, em casos multidimensionais) que aproxima os valores observados, minimizando a soma dos erros quadr√°ticos entre os valores previstos e os reais. 
    - Ele √© amplamente utilizado por ser simples, r√°pido de treinar e f√°cil de interpretar, sendo especialmente √∫til quando h√° uma tend√™ncia clara e linear nos dados, como prever pre√ßos de im√≥veis com base na √°rea ou estimar vendas com base em gastos com marketing.

1. **Regress√£o Log√≠stica**
    - √â um modelo estat√≠stico utilizado principalmente para problemas de classifica√ß√£o bin√°ria, embora possa ser estendido para classifica√ß√µes multiclasse. 
    - Diferente da regress√£o linear, que prev√™ valores cont√≠nuos, a regress√£o log√≠stica estima a probabilidade de uma inst√¢ncia pertencer a uma determinada classe (geralmente representada como 0 ou 1), usando a fun√ß√£o sigmoide para mapear os resultados em um intervalo entre 0 e 1. 
    - O modelo calcula uma combina√ß√£o linear das vari√°veis de entrada e aplica essa fun√ß√£o para obter a probabilidade de pertencimento √† classe positiva. 
    - Um limiar (geralmente 0,5) √© usado para converter essa probabilidade em uma previs√£o final. Sua simplicidade, boa interpretabilidade e efici√™ncia fazem dela uma escolha popular para problemas onde a rela√ß√£o entre as vari√°veis √© aproximadamente linear e o entendimento do modelo √© importante.
    
1. **Random Forest**
    - √© um modelo de aprendizado. Ele funciona criando um "floresta" de v√°rias √°rvores de decis√£o independentes, cada uma treinada em uma amostra aleat√≥ria dos dados (com reposi√ß√£o), e combinando suas previs√µes para melhorar a precis√£o e reduzir o risco de `overfitting`. 
    - Durante o treinamento, al√©m de sortear as amostras, ele tamb√©m seleciona aleatoriamente subconjuntos de caracter√≠sticas em cada divis√£o das √°rvores, aumentando ainda mais a diversidade entre elas. 
    - O resultado final √© dado pela m√©dia (em problemas de regress√£o) ou pela vota√ß√£o majorit√°ria (em classifica√ß√£o) das previs√µes de todas as √°rvores, tornando o `Random Forest` robusto, vers√°til e capaz de lidar bem com diferentes tipos de dados, mesmo na presen√ßa de ru√≠dos e vari√°veis irrelevantes.
    
1. **XGBoost**
    -  √© um modelo de aprendizado de m√°quina baseado na t√©cnica de boosting, sendo uma implementa√ß√£o otimizada e eficiente do Gradient Boosting. 
    - Ele constr√≥i √°rvores de decis√£o de forma sequencial, onde cada nova √°rvore corrige os erros cometidos pelas anteriores, resultando em um modelo final altamente preciso. 
    - O XGBoost se destaca por sua capacidade de lidar com diferentes tipos de dados (num√©ricos, categ√≥ricos), lidar bem com `overfitting` atrav√©s de regulariza√ß√µes, al√©m de ser r√°pido e escal√°vel gra√ßas a sua implementa√ß√£o paralelizada. 
    - √â amplamente utilizado em competi√ß√µes de `machine learning` e aplica√ß√µes reais por oferecer excelente desempenho em problemas de classifica√ß√£o e regress√£o.

1. **overfitting**
    - √© um problema comum em machine learning onde o modelo aprende demais os dados de treinamento, capturando n√£o apenas os padr√µes gerais, mas tamb√©m o ru√≠do e as particularidades dos exemplos espec√≠ficos. 
    - Isso faz com que o modelo tenha desempenho excelente nos dados de treino , mas muito ruim ao generalizar para novos dados ‚Äî ou seja, ele "decora" os exemplos em vez de aprender a reconhecer os verdadeiros padr√µes subjacentes. 
    - O overfitting ocorre principalmente quando o modelo √© muito complexo em rela√ß√£o √† quantidade ou simplicidade dos dados dispon√≠veis, como usar uma rede neural profunda com poucos dados de treinamento.

## üß™ Exemplo Pr√°tico: Classifica√ß√£o de Vinhos

**Problema:** Queremos classificar se um vinho √© "**bom**" ou "**ruim**" com base em atributos como **acidez**, **teor alco√≥lico**, **pH**, etc.

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Carregar dados (exemplo)
df = pd.read_csv('wine_quality.csv')

# Dividir em features e target
X = df.drop(columns='quality')
y = df['quality']

# Dividir em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Treinar modelo simples
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Avaliar
preds = model.predict(X_test)
print(f'Acur√°cia: {accuracy_score(y_test, preds):.2f}')
```

üéØ **Conclus√£o:** Para dados estruturados, modelos como **Random Forest** s√£o √≥timos por serem f√°ceis de treinar e interpretar.

---

## üì∏ Parte 2: Imagens ‚Äì Redes Neurais Convolucionais (CNN)

**Exemplo:** Identificar animais em fotos (cachorro, gato, p√°ssaro).

Modelos recomendados:
- **CNNs b√°sicas** (como `LeNet`, `AlexNet`)
- **Redes mais profundas** (`VGG`, `ResNet`, `EfficientNet`)


**Explica√ß√µes**:

1. A **LeNet** foi uma das primeiras redes neurais convolucionais desenvolvidas, criada por Yann LeCun em 1998. Foi projetada para reconhecer d√≠gitos escritos √† m√£o em imagens pequenas e em escala de cinza. Sua estrutura simples inclui camadas convolucionais seguidas de camadas de pooling e fully connected. Apesar de antiga, sentou as bases para o uso de CNNs em reconhecimento de padr√µes visuais.

1. A **AlexNet** , vencedora do ImageNet Challenge em 2012, foi um marco na era moderna do deep learning. Desenvolvida por Alex Krizhevsky e equipe, foi a primeira CNN profunda a superar significativamente m√©todos tradicionais em reconhecimento de imagens. Utiliza ReLU como fun√ß√£o de ativa√ß√£o, dropout para reduzir overfitting e √© treinada com GPU, permitindo lidar com imagens coloridas e mais classes.

1. Desenvolvida pela equipe da Oxford (**Visual Geometry Group**), a **VGG** se destaca pela simplicidade e uniformidade: usa apenas filtros 3x3 e 1x1, combinados com max pooling. Existem vers√µes com 16 ou 19 camadas (VGG16 e VGG19). Embora mais lenta e com mais par√¢metros que a AlexNet, sua arquitetura padronizada facilitou estudos e implementa√ß√µes em diversos projetos de vis√£o computacional.

1. A **ResNet**, vencedora do ImageNet em 2015, introduziu o conceito de skip connections (conex√µes residuais), permitindo o treinamento de redes muito profundas (at√© 152 camadas). Essas conex√µes permitem que o gradiente passe diretamente pelas camadas, evitando o problema do desaparecimento do gradiente. A ResNet revolucionou o design de arquiteturas profundas e se tornou amplamente adotada.

1. A **EfficientNet**, criada pelo Google, surgiu com a ideia de escalar a rede de forma balanceada ‚Äî aumentando profundidade, largura e resolu√ß√£o das imagens de maneira proporcional. Isso resulta em modelos que oferecem excelente desempenho com menor custo computacional. √â ideal para aplica√ß√µes onde efici√™ncia √© importante, como dispositivos m√≥veis ou embarcados. Possui varia√ß√µes como EfficientNet-B0 at√© B7, sendo cada uma mais pesada e precisa que a anterior.

### Por que usar CNN?
- Elas capturam padr√µes espaciais (formas, texturas).
- S√£o especializadas para imagens.

### Exemplo Simples com Keras:

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')  # Bin√°rio: cachorro ou gato
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Suponha que j√° temos os dados carregados
# model.fit(train_dataset, epochs=10)
```

üéØ **Conclus√£o:** Para imagens, **redes convolucionais (CNN)** s√£o quase sempre a primeira escolha.

---

## ‚úçÔ∏è Parte 3: Texto ‚Äì Processamento com NLP

**Exemplo:** Analisar sentimentos em `reviews` ("√≥timo", "terr√≠vel").

### Modelos Recomendados:
- **Bag-of-Words + Regress√£o Log√≠stica**
- **RNN / LSTM**
- **Transformers (BERT, GPT)**

:bulb: **Explica√ß√£o**:

- O **Bag-of-Words** 
    - √© uma t√©cnica simples e amplamente usada para representar texto como vetores num√©ricos, adapt√°veis ao processamento por algoritmos de machine learning. 
    - Ele funciona contando quantas vezes cada palavra aparece em um documento, ignorando a ordem das palavras e focando apenas na frequ√™ncia delas. 
    - Por exemplo, o texto "O gato correu atr√°s do rato" vira um vetor com as contagens de cada palavra. 
    - Apesar de perder informa√ß√µes sobre a estrutura e o contexto, o BoW √© √∫til para tarefas como classifica√ß√£o de textos e an√°lise de sentimentos, especialmente quando se usa t√©cnicas como TF-IDF para ponderar a import√¢ncia das palavras.


### Exemplo com BERT:

```python
from transformers import pipeline

# Carrega um modelo pr√©-treinado de an√°lise de sentimento
classifier = pipeline("sentiment-analysis")

# Testa com um exemplo
result = classifier("Este filme √© incr√≠vel!")[0]
print(f"Sentimento: {result['label']}, Confian√ßa: {round(result['score'], 2)}")
# Sa√≠da: Sentimento: POSITIVE, Confian√ßa: 0.999
```

üéØ **Conclus√£o:** Para tarefas complexas de linguagem natural, **transformers** como **BERT** oferecem performance superior.


## ‚è≥ Parte 4: S√©ries Temporais ‚Äì Padr√µes ao Longo do Tempo

**Exemplo:** Prever **valor do d√≥lar** nos pr√≥ximos 7 dias.

### Modelos Recomendados:
- **ARIMA** (simples e eficiente)
- **Prophet** (do Facebook, bom para sazonais)
- **LSTM / GRU** (redes recorrentes)
- **Transformers** (√∫ltima gera√ß√£o)

### Exemplo com Prophet:

```python
from fbprophet import Prophet
import pandas as pd

# Suponha que temos um DataFrame com datas e valores
df = pd.read_csv('sales_data.csv')  # Colunas: 'ds' e 'y'

# Treina o modelo
m = Prophet()
m.fit(df)

# Faz previs√£o para os pr√≥ximos 7 dias
future = m.make_future_dataframe(periods=7)
forecast = m.predict(future)

# Mostra resultados
print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())
```

üéØ **Conclus√£o:** Use **Prophet** para s√©ries regulares e **LSTM/Transformers** para padr√µes complexos.


## üíª Parte 5: Crit√©rios para Escolher a Arquitetura Certa

### 1. **Caracter√≠sticas dos Dados**
- Se s√£o **tabelas** ‚Üí use modelos cl√°ssicos (Random Forest, XGBoost).
- Se s√£o **imagens** ‚Üí use CNN.
- Se s√£o **textos** ‚Üí use Transformers.
- Se s√£o **s√©ries** ‚Üí use Prophet ou LSTM.

### 2. **Requisitos Computacionais**
- Modelos mais profundos (como redes neurais) exigem mais mem√≥ria e GPU.
- Modelos simples (como regress√£o log√≠stica) rodam em qualquer lugar.

### 3. **Trade-off Performance x Complexidade**
- Um modelo muito complexo pode **overfitar** (aprender demais os dados de treino).
- √Äs vezes, um modelo mais simples **funciona melhor na pr√°tica**.

**Explica√ß√£o**:

1. **overfitar** (`Overfitting`)
    - significa que um modelo de machine learning aprendeu excessivamente bem os dados de treinamento ‚Äî incluindo o ru√≠do, detalhes irrelevantes e at√© mesmo exce√ß√µes espec√≠ficas daquele conjunto.
    - Como resultado, ele se sai muito bem nos dados de treino, mas falha ao generalizar para novos dados. 
    - Isso acontece normalmente quando o modelo √© muito complexo em rela√ß√£o √† quantidade ou simplicidade dos dados dispon√≠veis. 
    - √â como se o aluno "decorasse" as respostas da prova sem entender o conte√∫do.

### 4. **Facilidade de Implementa√ß√£o**
- Alguns modelos t√™m bibliotecas prontas (ex: Scikit-Learn, TensorFlow, HuggingFace).
- Outros exigem implementa√ß√£o personalizada ou ajustes finos.

## ü§î Debate: Qual Modelo Escolher?

### Caso 1: Empresa de **E-commerce** quer prever compras futuras

- **Tipo de dado:** Hist√≥rico de compras (num√©rico, temporal)
- **Objetivo:** Previs√£o de demanda
- **Escolha poss√≠vel:** Prophet ou LSTM

üéØ **Discuss√£o:**  
- O que priorizar? Velocidade de implementa√ß√£o ou precis√£o?
- Tem recurso computacional? GPU dispon√≠vel?

### Caso 2: App m√≥vel que reconhece flores nas fotos

- **Tipo de dado:** Imagens
- **Objetivo:** Classifica√ß√£o visual
- **Escolha poss√≠vel:** MobileNet (leve e r√°pido)

üéØ **Discuss√£o:**  
- √â um app mobile ‚Üí n√£o pode usar modelos pesados.
- Precisa de boa performance com pouco recurso.


## üìå Checklist para Escolher a Melhor Arquitetura

‚úÖ **Passo 1:** Qual √© o t**ipo de dado (**estruturado, texto, imagem, s√©rie)?  
‚úÖ **Passo 2:** Qual √© o **objetivo** do modelo (classifica√ß√£o, regress√£o, detec√ß√£o)?  
‚úÖ **Passo 3:** Quais s√£o os re**cursos dispon√≠veis** (CPU/GPU, tempo, dados)?  
‚úÖ **Passo 4:** Qual n√≠vel de **performance** √© necess√°rio (precis√£o vs velocidade)?  
‚úÖ **Passo 5:** H√° bi**bliotecas prontas** para facilitar a implementa√ß√£o?


## üìö Resumo Final

| Tipo de Dado        | Boa Arquitetura Inicial         | Vantagens                           |
|---------------------|----------------------------------|--------------------------------------|
| Dados Estruturados  | Random Forest, XGBoost           | Simples, r√°pido, interpretabilidade |
| Imagens             | CNN (ex: ResNet, MobileNet)      | Excelente em padr√µes visuais        |
| Texto               | BERT, LSTM                       | Alta performance em linguagem       |
| S√©ries Temporais    | Prophet, LSTM                    | Captura tend√™ncias e sazonalidades  |

---

## üß© Atividade Sugerida

**Atividade:** Divida a turma em grupos e pe√ßa que cada grupo receba um cen√°rio diferente (ex: detectar fraudes em cart√µes, traduzir textos, prever estoque). Pe√ßam que eles:
1. Identifiquem o tipo de dado.
2. Sugiram poss√≠veis modelos.
3. Discutam trade-offs (performance x recursos).
4. Apresentem suas conclus√µes para a turma.

---

## üôã‚Äç‚ôÇÔ∏è D√∫vidas Frequentes

**Pergunta:** Posso usar deep learning para tudo?  
**Resposta:** 
    - Tecnicamente sim, mas nem sempre √© a melhor ideia. 
    - Deep learning exige mais dados e recursos. 
    - √Äs vezes, m√©todos simples s√£o suficientes.

**Pergunta:** Como saber se meu modelo est√° bom?  
**Resposta:** 
    - Avalie m√©tricas como **acur√°cia**, **precis√£o**, **recall**, **F1-score** ou **RMSE**, dependendo do problema.